{"cells":[{"cell_type":"code","execution_count":1,"id":"5593b8c4-f12b-4b91-b750-074a0fc29069","metadata":{"tags":[],"id":"5593b8c4-f12b-4b91-b750-074a0fc29069","outputId":"e5cfcfde-1c9f-4f5d-cde9-82e4938a48cf","colab":{"base_uri":"https://localhost:8080/","height":339},"executionInfo":{"status":"error","timestamp":1749378436581,"user_tz":420,"elapsed":2747,"user":{"displayName":"MARIE YANG","userId":"16411410987825159826"}}},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'language_speakers_3.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-121456b4f1c2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"language_speakers_3.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-1-121456b4f1c2>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m# 7. Updated main function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mlanguages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myears\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproportions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0mrecent_years\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myears\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myears\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2015\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mrecent_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproportions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myears\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2015\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-121456b4f1c2>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 1. Load data (unchanged)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coerce'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0myears\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'language_speakers_3.csv'"]}],"source":["import numpy as np\n","import pandas as pd\n","from scipy.integrate import solve_ivp\n","from scipy.optimize import minimize\n","import matplotlib.pyplot as plt\n","\n","# 1. Load data (unchanged)\n","def load_data(filename):\n","    df = pd.read_csv(filename, index_col=0)\n","    df = df.apply(pd.to_numeric, errors='coerce').fillna(0)\n","    years = df.columns.astype(int)\n","    absolute_data = df.values\n","    proportions = absolute_data / absolute_data.sum(axis=0)\n","    return df.index.tolist(), years, proportions\n","\n","# 2. AS model (unchanged)\n","def extended_as_model(t, x, s, a, beta):\n","    n = len(x)\n","    dxdt = np.zeros(n)\n","    epsilon = 1e-12\n","    for i in range(n):\n","        sum_gain = 0\n","        sum_loss = 0\n","        xi = max(x[i], epsilon)\n","        one_minus_xi = max(1 - xi, epsilon)\n","        for j in range(n):\n","            if i != j:\n","                xj = max(x[j], epsilon)\n","                one_minus_xj = max(1 - xj, epsilon)\n","                Pji = s[i] * xi**beta * one_minus_xj**(a - beta)\n","                Pij = s[j] * xj**beta * one_minus_xi**(a - beta)\n","                sum_gain += x[j] * Pji\n","                sum_loss += Pij\n","        dxdt[i] = sum_gain - x[i] * sum_loss\n","    return dxdt\n","\n","# 3. Simulate with tiny yearly shifts\n","def simulate_language_dynamics(x0, s, a, beta, t_span, t_eval):\n","    if callable(s):\n","        s_values = np.array([s(t) for t in t_eval])\n","    else:\n","        s_values = np.tile(s, (len(t_eval), 1))\n","\n","    sol = solve_ivp(extended_as_model, t_span, x0, args=(s_values[0], a, beta),\n","                    t_eval=[t_span[0]], method='LSODA')\n","\n","    for i in range(1, len(t_eval)):\n","        sol_i = solve_ivp(extended_as_model, [t_eval[i-1], t_eval[i]], sol.y[:, -1],\n","                         args=(s_values[i], a, beta), t_eval=[t_eval[i]], method='LSODA')\n","        sol.y = np.hstack((sol.y, sol_i.y))\n","        sol.t = np.hstack((sol.t, sol_i.t))\n","\n","    return sol.y\n","\n","# 4. New: Low-volatility status shifts\n","def gradual_status(t, base_s, volatility=0.01, mean_reversion=0.1):\n","    \"\"\"Tiny annual shifts with mean reversion to original status\"\"\"\n","    if not hasattr(gradual_status, 'last_s'):\n","        gradual_status.last_s = base_s.copy()\n","\n","    # Tiny random changes (volatility=0.01 is 1% max change)\n","    delta = volatility * (np.random.random(len(base_s)) - 0.5)  # Centered at 0\n","\n","    # Mean reversion pulls status back toward original values\n","    gradual_status.last_s += delta + mean_reversion * (base_s - gradual_status.last_s)\n","\n","    # Ensure valid probabilities\n","    gradual_status.last_s = np.clip(gradual_status.last_s, 0.001, 1.0)\n","    gradual_status.last_s /= np.sum(gradual_status.last_s)\n","\n","    return gradual_status.last_s\n","\n","# 5. Loss function\n","def loss_function_with_si(params, x_data, t_eval):\n","    a, beta = params[:2]\n","    s = params[2:]\n","    s = np.clip(s, 1e-6, 1.0)  # keep s values within [0, 1] to avoid instability\n","    s = s / np.sum(s)  # normalize so s behaves like probabilities\n","\n","    x0 = x_data[:, 0]\n","    x_model = simulate_language_dynamics(x0, s, a, beta, (t_eval[0], t_eval[-1]), t_eval)\n","    return np.mean((x_model - x_data) ** 2)\n","\n","# 6. Fit model\n","def fit_model_per_language(x_data, t_eval):\n","    n = x_data.shape[0]\n","    initial_s = np.ones(n) / n\n","    initial_params = np.concatenate(([1.0, 0.5], initial_s))  # [a, beta, s1, ..., sn]\n","\n","    bounds = [(0.01, 3.0), (0.01, 3.0)] + [(1e-6, 1.0)] * n  # bounds for a, beta, s_i\n","\n","    result = minimize(loss_function_with_si, initial_params, args=(x_data, t_eval),\n","                      bounds=bounds, method='L-BFGS-B')\n","\n","    a_fit, beta_fit = result.x[:2]\n","    s_fit = result.x[2:]\n","    s_fit /= np.sum(s_fit)  # ensure s is normalized\n","    print(f\"Optimization success: {result.success}, Loss: {result.fun}\")\n","    print(f\"a = {a_fit:.4f}, beta = {beta_fit:.4f}\")\n","    print(\"s =\", s_fit)\n","    return a_fit, beta_fit, s_fit\n","\n","# 7. Updated main function\n","def main(filename):\n","    languages, years, proportions = load_data(filename)\n","    recent_years = years[years >= 2015]\n","    recent_data = proportions[:, years >= 2015]\n","    a_fit, beta_fit, s_fit = fit_model_per_language(recent_data, recent_years)\n","\n","    forecast_start = years[-1]\n","    future_years = np.arange(forecast_start, forecast_start + 50, 1)\n","\n","    # Use gradual_status with very low volatility\n","    s_gradual = lambda t: gradual_status(t, s_fit, volatility=0.005, mean_reversion=0.05)\n","\n","    # Single simulation (for clean plot)\n","    x0 = proportions[:, -1]\n","    x_forecast = simulate_language_dynamics(\n","        x0, s_gradual, a_fit, beta_fit,\n","        (forecast_start, forecast_start + 50),\n","        future_years\n","    )\n","\n","    plt.figure(figsize=(12, 6))\n","    for i, lang in enumerate(languages):\n","        plt.plot(future_years, x_forecast[i], label=lang, alpha=0.8)\n","    plt.title('Language Projections with Gradual Status Changes')\n","    plt.xlabel('Year')\n","    plt.ylabel('Fraction of Speakers')\n","    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n","    plt.grid(True, linestyle=':', alpha=0.5)\n","    plt.tight_layout()\n","    plt.show()\n","\n","    # Uncertainty analysis (10 runs)\n","    n_simulations = 10\n","    all_simulations = np.zeros((n_simulations, len(languages), len(future_years)))\n","\n","    for sim in range(n_simulations):\n","        s_gradual = lambda t: gradual_status(t, s_fit, volatility=0.005)\n","        all_simulations[sim] = simulate_language_dynamics(\n","            x0, s_gradual, a_fit, beta_fit,\n","            (forecast_start, forecast_start + 50),\n","            future_years\n","        )\n","\n","    # Plot median and 25-75th percentiles\n","    plt.figure(figsize=(12, 6))\n","    for i, lang in enumerate(languages[:3]):  # First 3 languages\n","        median = np.median(all_simulations[:, i, :], axis=0)\n","        p25 = np.percentile(all_simulations[:, i, :], 25, axis=0)\n","        p75 = np.percentile(all_simulations[:, i, :], 75, axis=0)\n","        plt.plot(future_years, median, label=lang, lw=2)\n","        plt.fill_between(future_years, p25, p75, alpha=0.15)\n","\n","    plt.title('Projections with 25-75th Percentile Bands (Low Volatility)')\n","    plt.xlabel('Year')\n","    plt.ylabel('Fraction of Speakers')\n","    plt.legend()\n","    plt.show()\n","\n","main(\"language_speakers_3.csv\")"]},{"cell_type":"code","execution_count":null,"id":"f0047e0e-64b5-4e40-bc54-dd754e28f868","metadata":{"id":"f0047e0e-64b5-4e40-bc54-dd754e28f868"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}